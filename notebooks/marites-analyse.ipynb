{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6757cd5",
   "metadata": {},
   "source": [
    "# Marites Analyse\n",
    "\n",
    "## Overview\n",
    "Contains the logic for the analyse function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da1212e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import boto3\n",
    "from io import StringIO\n",
    "from uuid import uuid4\n",
    "\n",
    "load_dotenv()\n",
    "print(\"Import complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f6fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_twitter_posts = 100\n",
    "max_following = 250\n",
    "token = os.environ.get(\"BEARER_TOKEN\")\n",
    "test_username = 'elonmusk'\n",
    "\n",
    "region = 'ap-southeast-1'\n",
    "language_code = 'en'\n",
    "input_bucket = 'marites-comprehend-input'\n",
    "output_bucket = 'marites-comprehend-output'\n",
    "data_access_role_arn = os.environ.get(\"DATA_ACCESS_ROLE\")\n",
    "input_doc_format = 'ONE_DOC_PER_LINE'\n",
    "\n",
    "tg_input_folder = 'tigergraph' \n",
    "comprehend_input_folder = 'comprehend'\n",
    "\n",
    "session_id = uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e066e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Functions\n",
    "\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "following_url = \"https://api.twitter.com/2/users/{}/following\"\n",
    "lookup_username_url = \"https://api.twitter.com/2/users/by/username/{}\"\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {token}\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def fetch_user_by_username(username):\n",
    "    url = lookup_username_url.format(username)\n",
    "    response = requests.get(url, auth=bearer_oauth)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    json_res = response.json()\n",
    "    return json_res['data']\n",
    "\n",
    "def map_tweets_to_post(raw_data):\n",
    "    if 'data' not in raw_data:\n",
    "        return []\n",
    "\n",
    "    tweets = raw_data['data']\n",
    "    username = raw_data['includes']['users'][0]['username']\n",
    "    ref_tweets = { tweet['id']: tweet['text'] for tweet in raw_data['includes']['tweets'] } if 'includes' in raw_data and 'tweets' in raw_data['includes'] else {}\n",
    "    \n",
    "    results = []\n",
    "    for t in tweets:\n",
    "        post = { \n",
    "            'tweet_id': t['id'],\n",
    "            'username': username,\n",
    "            'created_at': t['created_at']\n",
    "        }\n",
    "        if 'referenced_tweets' in t:\n",
    "            combined_text = []\n",
    "            for rt in t['referenced_tweets']:\n",
    "                rt_id = rt['id']\n",
    "                if rt_id in ref_tweets:\n",
    "                    rt_text = ref_tweets[rt_id]\n",
    "                    combined_text.append(rt_text)\n",
    "            post['text'] = ' '.join(combined_text)\n",
    "        else:\n",
    "            post['text'] = t['text']\n",
    "\n",
    "        results.append(post)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def fetch_tweets_by_username(username):\n",
    "    params = {\n",
    "        \"query\": \"from:{} -is:reply\".format(username),\n",
    "        \"max_results\": max_twitter_posts,\n",
    "        \"expansions\": \"referenced_tweets.id,author_id\",\n",
    "        \"tweet.fields\": \"created_at\",\n",
    "        \"user.fields\": \"username\"\n",
    "    }\n",
    "    response = requests.get(search_url, auth=bearer_oauth, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    data = response.json()\n",
    "    return map_tweets_to_post(data)\n",
    "\n",
    "def fetch_following(user_id):\n",
    "    url = following_url.format(user_id)\n",
    "    params = {\n",
    "        'max_results': max_following\n",
    "    }\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    json_res = response.json()\n",
    "    return json_res['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f62234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter data extraction\n",
    "\n",
    "def get_user_tweets(users_to_search):\n",
    "    processed = 0\n",
    "    all_tweets = []\n",
    "    for user in users_to_search:\n",
    "        user_tweets = fetch_tweets_by_username(user)\n",
    "        processed += 1\n",
    "        all_tweets.extend(user_tweets)\n",
    "        progress = round((processed / len(users_to_search)) * 100, 2)\n",
    "        print(\"Processed {}/{} users ({}%)\".format(processed, len(users_to_search), progress))\n",
    "    user_tweets = pd.DataFrame(all_tweets)\n",
    "    return user_tweets\n",
    "\n",
    "def get_user_following_map(user, following):\n",
    "    date = datetime.now().strftime(\"%m-%d-%y\")\n",
    "    username = user['username']\n",
    "    follow_names = list(map(lambda x: x['username'], following))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'user': [username] * len(following),\n",
    "        'following': follow_names,\n",
    "        'date': [date] * len(following)\n",
    "    })\n",
    "\n",
    "\n",
    "def clean_posts(data):\n",
    "    user_tweets = data\n",
    "    \n",
    "    # Clean up the links from the text (they're useless to us)\n",
    "    user_tweets['text'] = user_tweets['text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "\n",
    "    # Remove all emojis\n",
    "    user_tweets = user_tweets.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "\n",
    "    # Remove blank tweets\n",
    "    user_tweets = user_tweets[user_tweets.text.str.strip().str.len() != 0]\n",
    "\n",
    "    # Ensure that all text is in a single line\n",
    "    user_tweets.text = user_tweets.text.str.replace('\\n', ' ');\n",
    "    user_tweets.text = user_tweets.text.str.replace('\\r', ' ');\n",
    "    \n",
    "    return user_tweets\n",
    "\n",
    "def extract_twitter_data(username):\n",
    "    users_list = []\n",
    "    user = fetch_user_by_username(username)\n",
    "    user_following = fetch_following(user['id'])\n",
    "\n",
    "    users_list.append(user)\n",
    "    users_list.extend(user_following)\n",
    "    \n",
    "    users_to_search = list(map(lambda x: x['username'], users_list))\n",
    "    \n",
    "    posts_df = get_user_tweets(users_to_search)\n",
    "    following_df = get_user_following_map(user, user_following) # user -> following edges\n",
    "    users_df = pd.DataFrame(users_list) # users vertex\n",
    "    \n",
    "    return {\n",
    "        'posts': clean_posts(posts_df),\n",
    "        'following': following_df,\n",
    "        'users': users_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36785355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/114 users (0.88%)\n",
      "Processed 2/114 users (1.75%)\n",
      "Processed 3/114 users (2.63%)\n",
      "Processed 4/114 users (3.51%)\n",
      "Processed 5/114 users (4.39%)\n",
      "Processed 6/114 users (5.26%)\n",
      "Processed 7/114 users (6.14%)\n",
      "Processed 8/114 users (7.02%)\n",
      "Processed 9/114 users (7.89%)\n",
      "Processed 10/114 users (8.77%)\n",
      "Processed 11/114 users (9.65%)\n",
      "Processed 12/114 users (10.53%)\n",
      "Processed 13/114 users (11.4%)\n",
      "Processed 14/114 users (12.28%)\n",
      "Processed 15/114 users (13.16%)\n",
      "Processed 16/114 users (14.04%)\n",
      "Processed 17/114 users (14.91%)\n",
      "Processed 18/114 users (15.79%)\n",
      "Processed 19/114 users (16.67%)\n",
      "Processed 20/114 users (17.54%)\n",
      "Processed 21/114 users (18.42%)\n",
      "Processed 22/114 users (19.3%)\n",
      "Processed 23/114 users (20.18%)\n",
      "Processed 24/114 users (21.05%)\n",
      "Processed 25/114 users (21.93%)\n",
      "Processed 26/114 users (22.81%)\n",
      "Processed 27/114 users (23.68%)\n",
      "Processed 28/114 users (24.56%)\n",
      "Processed 29/114 users (25.44%)\n",
      "Processed 30/114 users (26.32%)\n",
      "Processed 31/114 users (27.19%)\n",
      "Processed 32/114 users (28.07%)\n",
      "Processed 33/114 users (28.95%)\n",
      "Processed 34/114 users (29.82%)\n",
      "Processed 35/114 users (30.7%)\n",
      "Processed 36/114 users (31.58%)\n",
      "Processed 37/114 users (32.46%)\n",
      "Processed 38/114 users (33.33%)\n",
      "Processed 39/114 users (34.21%)\n",
      "Processed 40/114 users (35.09%)\n",
      "Processed 41/114 users (35.96%)\n",
      "Processed 42/114 users (36.84%)\n",
      "Processed 43/114 users (37.72%)\n",
      "Processed 44/114 users (38.6%)\n",
      "Processed 45/114 users (39.47%)\n",
      "Processed 46/114 users (40.35%)\n",
      "Processed 47/114 users (41.23%)\n",
      "Processed 48/114 users (42.11%)\n",
      "Processed 49/114 users (42.98%)\n",
      "Processed 50/114 users (43.86%)\n",
      "Processed 51/114 users (44.74%)\n",
      "Processed 52/114 users (45.61%)\n",
      "Processed 53/114 users (46.49%)\n",
      "Processed 54/114 users (47.37%)\n",
      "Processed 55/114 users (48.25%)\n",
      "Processed 56/114 users (49.12%)\n",
      "Processed 57/114 users (50.0%)\n",
      "Processed 58/114 users (50.88%)\n",
      "Processed 59/114 users (51.75%)\n",
      "Processed 60/114 users (52.63%)\n",
      "Processed 61/114 users (53.51%)\n",
      "Processed 62/114 users (54.39%)\n",
      "Processed 63/114 users (55.26%)\n",
      "Processed 64/114 users (56.14%)\n",
      "Processed 65/114 users (57.02%)\n",
      "Processed 66/114 users (57.89%)\n",
      "Processed 67/114 users (58.77%)\n",
      "Processed 68/114 users (59.65%)\n",
      "Processed 69/114 users (60.53%)\n",
      "Processed 70/114 users (61.4%)\n",
      "Processed 71/114 users (62.28%)\n",
      "Processed 72/114 users (63.16%)\n",
      "Processed 73/114 users (64.04%)\n",
      "Processed 74/114 users (64.91%)\n",
      "Processed 75/114 users (65.79%)\n",
      "Processed 76/114 users (66.67%)\n",
      "Processed 77/114 users (67.54%)\n",
      "Processed 78/114 users (68.42%)\n",
      "Processed 79/114 users (69.3%)\n",
      "Processed 80/114 users (70.18%)\n",
      "Processed 81/114 users (71.05%)\n",
      "Processed 82/114 users (71.93%)\n",
      "Processed 83/114 users (72.81%)\n",
      "Processed 84/114 users (73.68%)\n",
      "Processed 85/114 users (74.56%)\n",
      "Processed 86/114 users (75.44%)\n",
      "Processed 87/114 users (76.32%)\n",
      "Processed 88/114 users (77.19%)\n",
      "Processed 89/114 users (78.07%)\n",
      "Processed 90/114 users (78.95%)\n",
      "Processed 91/114 users (79.82%)\n",
      "Processed 92/114 users (80.7%)\n",
      "Processed 93/114 users (81.58%)\n",
      "Processed 94/114 users (82.46%)\n",
      "Processed 95/114 users (83.33%)\n",
      "Processed 96/114 users (84.21%)\n",
      "Processed 97/114 users (85.09%)\n",
      "Processed 98/114 users (85.96%)\n",
      "Processed 99/114 users (86.84%)\n",
      "Processed 100/114 users (87.72%)\n",
      "Processed 101/114 users (88.6%)\n",
      "Processed 102/114 users (89.47%)\n",
      "Processed 103/114 users (90.35%)\n",
      "Processed 104/114 users (91.23%)\n",
      "Processed 105/114 users (92.11%)\n",
      "Processed 106/114 users (92.98%)\n",
      "Processed 107/114 users (93.86%)\n",
      "Processed 108/114 users (94.74%)\n",
      "Processed 109/114 users (95.61%)\n",
      "Processed 110/114 users (96.49%)\n",
      "Processed 111/114 users (97.37%)\n",
      "Processed 112/114 users (98.25%)\n",
      "Processed 113/114 users (99.12%)\n",
      "Processed 114/114 users (100.0%)\n"
     ]
    }
   ],
   "source": [
    "data = extract_twitter_data(test_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76a5047c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>line_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1512886651940491270</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>2022-04-09T20:14:20.000Z</td>\n",
       "      <td>69.420% of statistics are false</td>\n",
       "      <td>0-elonmusk</td>\n",
       "      <td>elonmusk-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1512886157876600833</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>2022-04-09T20:12:22.000Z</td>\n",
       "      <td>Truth is the first casualty.</td>\n",
       "      <td>1-elonmusk</td>\n",
       "      <td>elonmusk-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1512813698011836422</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>2022-04-09T15:24:26.000Z</td>\n",
       "      <td>Thank you to everyone who came out to celebrat...</td>\n",
       "      <td>2-elonmusk</td>\n",
       "      <td>elonmusk-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512787864458870787</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>2022-04-09T13:41:47.000Z</td>\n",
       "      <td>Docking confirmed!</td>\n",
       "      <td>3-elonmusk</td>\n",
       "      <td>elonmusk-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1512785529712123906</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>2022-04-09T13:32:31.000Z</td>\n",
       "      <td>TOP 10 most followed Twitter accounts:    1. @...</td>\n",
       "      <td>4-elonmusk</td>\n",
       "      <td>elonmusk-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>1512405019013763076</td>\n",
       "      <td>SpaceX</td>\n",
       "      <td>2022-04-08T12:20:30.000Z</td>\n",
       "      <td>Ax-1 crew arrives at historic Launch Complex 3...</td>\n",
       "      <td>2512-elonmusk</td>\n",
       "      <td>elonmusk-2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>1512398808537186304</td>\n",
       "      <td>SpaceX</td>\n",
       "      <td>2022-04-08T11:55:49.000Z</td>\n",
       "      <td>Watch Falcon 9 launch @Axiom_Spaces Ax-1 missi...</td>\n",
       "      <td>2513-elonmusk</td>\n",
       "      <td>elonmusk-2513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>1512360477988634625</td>\n",
       "      <td>SpaceX</td>\n",
       "      <td>2022-04-08T09:23:30.000Z</td>\n",
       "      <td>Targeting 11:17 a.m. ET for todays Falcon 9 la...</td>\n",
       "      <td>2514-elonmusk</td>\n",
       "      <td>elonmusk-2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>1512065240116072466</td>\n",
       "      <td>SpaceX</td>\n",
       "      <td>2022-04-07T13:50:20.000Z</td>\n",
       "      <td>All systems are looking good for tomorrows Fal...</td>\n",
       "      <td>2515-elonmusk</td>\n",
       "      <td>elonmusk-2515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>1511784137861988356</td>\n",
       "      <td>SpaceX</td>\n",
       "      <td>2022-04-06T19:13:20.000Z</td>\n",
       "      <td>Static fire test of Falcon 9 complete  targeti...</td>\n",
       "      <td>2516-elonmusk</td>\n",
       "      <td>elonmusk-2516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2350 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id  username                created_at  \\\n",
       "0     1512886651940491270  elonmusk  2022-04-09T20:14:20.000Z   \n",
       "1     1512886157876600833  elonmusk  2022-04-09T20:12:22.000Z   \n",
       "2     1512813698011836422  elonmusk  2022-04-09T15:24:26.000Z   \n",
       "3     1512787864458870787  elonmusk  2022-04-09T13:41:47.000Z   \n",
       "4     1512785529712123906  elonmusk  2022-04-09T13:32:31.000Z   \n",
       "...                   ...       ...                       ...   \n",
       "2512  1512405019013763076    SpaceX  2022-04-08T12:20:30.000Z   \n",
       "2513  1512398808537186304    SpaceX  2022-04-08T11:55:49.000Z   \n",
       "2514  1512360477988634625    SpaceX  2022-04-08T09:23:30.000Z   \n",
       "2515  1512065240116072466    SpaceX  2022-04-07T13:50:20.000Z   \n",
       "2516  1511784137861988356    SpaceX  2022-04-06T19:13:20.000Z   \n",
       "\n",
       "                                                   text             id  \\\n",
       "0                       69.420% of statistics are false     0-elonmusk   \n",
       "1                         Truth is the first casualty.      1-elonmusk   \n",
       "2     Thank you to everyone who came out to celebrat...     2-elonmusk   \n",
       "3                                   Docking confirmed!      3-elonmusk   \n",
       "4     TOP 10 most followed Twitter accounts:    1. @...     4-elonmusk   \n",
       "...                                                 ...            ...   \n",
       "2512  Ax-1 crew arrives at historic Launch Complex 3...  2512-elonmusk   \n",
       "2513  Watch Falcon 9 launch @Axiom_Spaces Ax-1 missi...  2513-elonmusk   \n",
       "2514  Targeting 11:17 a.m. ET for todays Falcon 9 la...  2514-elonmusk   \n",
       "2515  All systems are looking good for tomorrows Fal...  2515-elonmusk   \n",
       "2516  Static fire test of Falcon 9 complete  targeti...  2516-elonmusk   \n",
       "\n",
       "            line_id  \n",
       "0        elonmusk-0  \n",
       "1        elonmusk-1  \n",
       "2        elonmusk-2  \n",
       "3        elonmusk-3  \n",
       "4        elonmusk-4  \n",
       "...             ...  \n",
       "2512  elonmusk-2512  \n",
       "2513  elonmusk-2513  \n",
       "2514  elonmusk-2514  \n",
       "2515  elonmusk-2515  \n",
       "2516  elonmusk-2516  \n",
       "\n",
       "[2350 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = data['posts']\n",
    "posts['line_id'] = posts.index.map(lambda x: '{}-{}'.format(test_username, x))\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2ae181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehend analysis\n",
    "\n",
    "def upload_text_to_s3(data, bucket_name, file_name):\n",
    "    text_buffer = StringIO()\n",
    "    data.text.to_csv(text_buffer, sep=' ', index=False, header=False)\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    return s3_resource.Object(bucket_name, '{}.txt'.format(file_name)).put(Body=text_buffer.getvalue())\n",
    "\n",
    "def upload_csv_to_s3(data, bucket_name, file_name):\n",
    "    buffer = StringIO()\n",
    "    data.to_csv(buffer, index=False)\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    return s3_resource.Object(bucket_name, '{}.csv'.format(file_name)).put(Body=buffer.getvalue())\n",
    "\n",
    "def start_targeted_sentiment_job(input_s3_url, output_s3_url, job_tag):\n",
    "    input_data_config = {\n",
    "        'S3Uri': input_s3_url,\n",
    "        'InputFormat': input_doc_format\n",
    "    }\n",
    "\n",
    "    output_data_config = {\n",
    "        'S3Uri': output_s3_url\n",
    "    }\n",
    "\n",
    "    job_name = 'Targeted_Sentiment_Job_{}'.format(job_tag)\n",
    "    \n",
    "    comprehend = boto3.client('comprehend', region_name=region)\n",
    "    return comprehend.start_targeted_sentiment_detection_job(InputDataConfig=input_data_config,\n",
    "                                                             OutputDataConfig=output_data_config, \n",
    "                                                             DataAccessRoleArn=data_access_role_arn, \n",
    "                                                             LanguageCode=language_code,\n",
    "                                                             JobName=job_name)\n",
    "\n",
    "def analyse_tweets(username):\n",
    "    date = datetime.now().strftime(\"%m-%d-%y\")\n",
    "    tag = \"{}-{}\".format(date, username)\n",
    "    \n",
    "    twitter_data = extract_twitter_data(username)\n",
    "\n",
    "    posts = twitter_data['posts']\n",
    "    posts['line_id'] = posts.index.map(lambda x: '{}-{}'.format(x, tag)) # used for mapping entities\n",
    "\n",
    "    following = twitter_data['following']\n",
    "    users = twitter_data['users']\n",
    "    \n",
    "    session_folder = '{}/{}'.format(session_id, username)\n",
    "    tg_folder = '{}/{}'.format(tg_input_folder, session_folder) # Tigergraph files\n",
    "    comp_folder = '{}/{}'.format(comprehend_input_folder, session_folder) # Comprehend files\n",
    "\n",
    "    posts_filename = 'posts'\n",
    "    following_filename = 'following'\n",
    "    users_filename = 'users'\n",
    "    \n",
    "    # Upload data to Comprehend input folder\n",
    "    print(\"Uploading comprehend input files...\")\n",
    "    upload_text_to_s3(posts, input_bucket, '{}/{}_{}'.format(comp_folder, posts_filename, tag))\n",
    "    \n",
    "    print(\"Uploading Tigergraph input files...\")\n",
    "    # Upload data to Tigergraph input folder\n",
    "    upload_csv_to_s3(posts, input_bucket, '{}/{}'.format(tg_folder, posts_filename))\n",
    "    upload_csv_to_s3(following, input_bucket, '{}/{}'.format(tg_folder, following_filename))\n",
    "    upload_csv_to_s3(users, input_bucket, '{}/{}'.format(tg_folder, users_filename))\n",
    "    \n",
    "    print(\"Starting comprehend job...\")\n",
    "    # Start comprehend job\n",
    "    input_s3_url = 's3://{}/{}'.format(input_bucket, comp_folder)\n",
    "    output_s3_url = 's3://{}/{}'.format(output_bucket, session_folder)\n",
    "    return start_targeted_sentiment_job(input_s3_url, output_s3_url, tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ee03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/114 users (0.88%)\n",
      "Processed 2/114 users (1.75%)\n",
      "Processed 3/114 users (2.63%)\n",
      "Processed 4/114 users (3.51%)\n",
      "Processed 5/114 users (4.39%)\n",
      "Processed 6/114 users (5.26%)\n",
      "Processed 7/114 users (6.14%)\n",
      "Processed 8/114 users (7.02%)\n",
      "Processed 9/114 users (7.89%)\n",
      "Processed 10/114 users (8.77%)\n",
      "Processed 11/114 users (9.65%)\n",
      "Processed 12/114 users (10.53%)\n",
      "Processed 13/114 users (11.4%)\n",
      "Processed 14/114 users (12.28%)\n",
      "Processed 15/114 users (13.16%)\n",
      "Processed 16/114 users (14.04%)\n",
      "Processed 17/114 users (14.91%)\n",
      "Processed 18/114 users (15.79%)\n",
      "Processed 19/114 users (16.67%)\n",
      "Processed 20/114 users (17.54%)\n",
      "Processed 21/114 users (18.42%)\n",
      "Processed 22/114 users (19.3%)\n",
      "Processed 23/114 users (20.18%)\n",
      "Processed 24/114 users (21.05%)\n",
      "Processed 25/114 users (21.93%)\n",
      "Processed 26/114 users (22.81%)\n",
      "Processed 27/114 users (23.68%)\n",
      "Processed 28/114 users (24.56%)\n",
      "Processed 29/114 users (25.44%)\n",
      "Processed 30/114 users (26.32%)\n",
      "Processed 31/114 users (27.19%)\n",
      "Processed 32/114 users (28.07%)\n",
      "Processed 33/114 users (28.95%)\n",
      "Processed 34/114 users (29.82%)\n",
      "Processed 35/114 users (30.7%)\n",
      "Processed 36/114 users (31.58%)\n",
      "Processed 37/114 users (32.46%)\n",
      "Processed 38/114 users (33.33%)\n",
      "Processed 39/114 users (34.21%)\n",
      "Processed 40/114 users (35.09%)\n",
      "Processed 41/114 users (35.96%)\n",
      "Processed 42/114 users (36.84%)\n",
      "Processed 43/114 users (37.72%)\n",
      "Processed 44/114 users (38.6%)\n",
      "Processed 45/114 users (39.47%)\n",
      "Processed 46/114 users (40.35%)\n",
      "Processed 47/114 users (41.23%)\n",
      "Processed 48/114 users (42.11%)\n",
      "Processed 49/114 users (42.98%)\n",
      "Processed 50/114 users (43.86%)\n",
      "Processed 51/114 users (44.74%)\n",
      "Processed 52/114 users (45.61%)\n",
      "Processed 53/114 users (46.49%)\n",
      "Processed 54/114 users (47.37%)\n",
      "Processed 55/114 users (48.25%)\n",
      "Processed 56/114 users (49.12%)\n",
      "Processed 57/114 users (50.0%)\n",
      "Processed 58/114 users (50.88%)\n",
      "Processed 59/114 users (51.75%)\n",
      "Processed 60/114 users (52.63%)\n",
      "Processed 61/114 users (53.51%)\n",
      "Processed 62/114 users (54.39%)\n",
      "Processed 63/114 users (55.26%)\n",
      "Processed 64/114 users (56.14%)\n",
      "Processed 65/114 users (57.02%)\n",
      "Processed 66/114 users (57.89%)\n",
      "Processed 67/114 users (58.77%)\n",
      "Processed 68/114 users (59.65%)\n",
      "Processed 69/114 users (60.53%)\n",
      "Processed 70/114 users (61.4%)\n",
      "Processed 71/114 users (62.28%)\n",
      "Processed 72/114 users (63.16%)\n",
      "Processed 73/114 users (64.04%)\n",
      "Processed 74/114 users (64.91%)\n",
      "Processed 75/114 users (65.79%)\n",
      "Processed 76/114 users (66.67%)\n",
      "Processed 77/114 users (67.54%)\n",
      "Processed 78/114 users (68.42%)\n",
      "Processed 79/114 users (69.3%)\n",
      "Processed 80/114 users (70.18%)\n",
      "Processed 81/114 users (71.05%)\n",
      "Processed 82/114 users (71.93%)\n",
      "Processed 83/114 users (72.81%)\n",
      "Processed 84/114 users (73.68%)\n",
      "Processed 85/114 users (74.56%)\n",
      "Processed 86/114 users (75.44%)\n",
      "Processed 87/114 users (76.32%)\n",
      "Processed 88/114 users (77.19%)\n",
      "Processed 89/114 users (78.07%)\n",
      "Processed 90/114 users (78.95%)\n",
      "Processed 91/114 users (79.82%)\n",
      "Processed 92/114 users (80.7%)\n",
      "Processed 93/114 users (81.58%)\n",
      "Processed 94/114 users (82.46%)\n",
      "Processed 95/114 users (83.33%)\n",
      "Processed 96/114 users (84.21%)\n",
      "Processed 97/114 users (85.09%)\n",
      "Processed 98/114 users (85.96%)\n",
      "Processed 99/114 users (86.84%)\n",
      "Processed 100/114 users (87.72%)\n",
      "Processed 101/114 users (88.6%)\n",
      "Processed 102/114 users (89.47%)\n",
      "Processed 103/114 users (90.35%)\n",
      "Processed 104/114 users (91.23%)\n",
      "Processed 105/114 users (92.11%)\n",
      "Processed 106/114 users (92.98%)\n",
      "Processed 107/114 users (93.86%)\n",
      "Processed 108/114 users (94.74%)\n",
      "Processed 109/114 users (95.61%)\n",
      "Processed 110/114 users (96.49%)\n",
      "Processed 111/114 users (97.37%)\n",
      "Processed 112/114 users (98.25%)\n",
      "Processed 113/114 users (99.12%)\n",
      "Processed 114/114 users (100.0%)\n",
      "Uploading comprehend input files...\n",
      "Uploading Tigergraph input files...\n",
      "Starting comprehend job...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'JobId': '446eb8136a44259c95fc82dfbddd1e8b',\n",
       " 'JobArn': 'arn:aws:comprehend:ap-southeast-1:368767127050:targeted-sentiment-detection-job/446eb8136a44259c95fc82dfbddd1e8b',\n",
       " 'JobStatus': 'SUBMITTED',\n",
       " 'ResponseMetadata': {'RequestId': '6c634d5b-0744-412c-a2fa-56eed7ab150d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '6c634d5b-0744-412c-a2fa-56eed7ab150d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '192',\n",
       "   'date': 'Thu, 14 Apr 2022 05:10:25 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_tweets(test_username)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
