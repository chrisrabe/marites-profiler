{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2df02b8",
   "metadata": {},
   "source": [
    "# Tarfile Test\n",
    "\n",
    "## Overview\n",
    "Just experimenting with combining multiple pandas Dataframe into a single tarfile and uploading it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "66d97441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "from io import BytesIO\n",
    "from tempfile import TemporaryDirectory\n",
    "import boto3\n",
    "\n",
    "print(\"Import complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b6e8df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "input_bucket = 'marites-comprehend-input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84fe6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes intended to be pushed\n",
    "users = pd.read_csv('users.csv')\n",
    "following = pd.read_csv('following.csv')\n",
    "posts = pd.read_csv('posts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b01e52",
   "metadata": {},
   "source": [
    "## Write archive to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e1cac473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames(tar_filename, frame_dict):\n",
    "    tar_buffer = BytesIO()\n",
    "    \n",
    "    # Create a tarfile into which frames can be added\n",
    "    with tarfile.open(fileobj=tar_buffer, mode='w:gz') as tfo:\n",
    "    \n",
    "        # Loop over all dataframes to be saved\n",
    "        for file_name, df in frame_dict.items():\n",
    "\n",
    "            # Compute the full path of the output file within the archive\n",
    "            archive_name = os.path.join(tar_filename, file_name)\n",
    "\n",
    "            # Create a temporary directory for packaging into a tar_file\n",
    "            with TemporaryDirectory(prefix='rev_processing__') as temp_dir:\n",
    "                \n",
    "                # Write a csv dump of the dataframe to a temporary file\n",
    "                temp_file_name = os.path.join(temp_dir, archive_name)\n",
    "                os.makedirs(os.path.dirname(temp_file_name), exist_ok=True)\n",
    "                df.to_csv(temp_file_name, index=False)\n",
    "\n",
    "                # Add the temp file to the tarfile\n",
    "                tfo.add(temp_file_name, arcname=archive_name)\n",
    "    \n",
    "    return tar_buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "96ce4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "archived_frames = save_frames('output', { 'users.csv': users, 'following.csv': following, 'posts.csv': posts })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b69772d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'XX2DVH1APB7P73DV',\n",
       "  'HostId': 'Z+OLXX/9q7B45i+sLlFVylv2csl4P5kKsXLd2GAN/Mrz0nCAMslHQTkF6NYg5pxh09xroVJah3k=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'Z+OLXX/9q7B45i+sLlFVylv2csl4P5kKsXLd2GAN/Mrz0nCAMslHQTkF6NYg5pxh09xroVJah3k=',\n",
       "   'x-amz-request-id': 'XX2DVH1APB7P73DV',\n",
       "   'date': 'Fri, 15 Apr 2022 01:49:15 GMT',\n",
       "   'x-amz-expiration': 'expiry-date=\"Sun, 17 Apr 2022 00:00:00 GMT\", rule-id=\"comprehend-bucket-lifecycle\"',\n",
       "   'etag': '\"8b2057cabb75509a30d9dff064ad2472\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Expiration': 'expiry-date=\"Sun, 17 Apr 2022 00:00:00 GMT\", rule-id=\"comprehend-bucket-lifecycle\"',\n",
       " 'ETag': '\"8b2057cabb75509a30d9dff064ad2472\"'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'tigergraph/output.tar.gz'\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(input_bucket, filename).put(Body=archived_frames.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990b628",
   "metadata": {},
   "source": [
    "## Read Archive from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "95e62146",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "input_tar_file = s3_client.get_object(Bucket=input_bucket, Key=filename)\n",
    "input_tar_content = input_tar_file['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "32101dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id                  name         username\n",
      "0            44196397             Elon Musk         elonmusk\n",
      "1            34097500                beeple           beeple\n",
      "2           276540738  ùîäùîØùî¶ùî™ùî¢ùî∞ (‚åõÔ∏è,‚è≥) ·ö∑·ö±·õÅ·õó·õñ·õã         Grimezsz\n",
      "3          1231406720        Michael Sheetz  thesheetztweetz\n",
      "4  959471389282578432         Eva Fox ü¶ä‚ù§Ô∏èüá∫üá¶          EvaFoxU\n",
      "       user        following      date\n",
      "0  elonmusk           beeple  04-14-22\n",
      "1  elonmusk         Grimezsz  04-14-22\n",
      "2  elonmusk  thesheetztweetz  04-14-22\n",
      "3  elonmusk          EvaFoxU  04-14-22\n",
      "4  elonmusk           planet  04-14-22\n",
      "              tweet_id  username                created_at  \\\n",
      "0  1512886651940491270  elonmusk  2022-04-09T20:14:20.000Z   \n",
      "1  1512886157876600833  elonmusk  2022-04-09T20:12:22.000Z   \n",
      "2  1512813698011836422  elonmusk  2022-04-09T15:24:26.000Z   \n",
      "3  1512787864458870787  elonmusk  2022-04-09T13:41:47.000Z   \n",
      "4  1512785529712123906  elonmusk  2022-04-09T13:32:31.000Z   \n",
      "\n",
      "                                                text              line_id  \n",
      "0                    69.420% of statistics are false  0-04-14-22-elonmusk  \n",
      "1                      Truth is the first casualty.   1-04-14-22-elonmusk  \n",
      "2  Thank you to everyone who came out to celebrat...  2-04-14-22-elonmusk  \n",
      "3                                Docking confirmed!   3-04-14-22-elonmusk  \n",
      "4  TOP 10 most followed Twitter accounts:    1. @...  4-04-14-22-elonmusk  \n"
     ]
    }
   ],
   "source": [
    "tar = tarfile.open(fileobj=BytesIO(input_tar_content))\n",
    "\n",
    "for tar_resource in tar:\n",
    "    filename = tar_resource.name\n",
    "    df = pd.read_csv(tar.extractfile(tar_resource), header=0)\n",
    "    print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
